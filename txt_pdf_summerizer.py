# -*- coding: utf-8 -*-
"""txt_pdf_summerizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XOPhHkw3HUhWxDlZHlRKU1zCh_AKn_aj
"""

# â–“â–“  Single-model PDF/TXT summariser  (default: LLaMA-4 Maverick)  â–“â–“
# Install once per Colab session:
# !pip install -q --upgrade openai pdfplumber tqdm
!pip install -q --upgrade openai pdfplumber tqdm
import os, io, textwrap, pdfplumber
from google.colab import files
from tqdm.auto import tqdm
from openai import OpenAI, OpenAIError

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£  Interactive settings (one primary model only)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("âœï¸  Configure run â€” press Enter for values in [brackets]")
api_key  = input("ğŸ”‘  OpenAI / OpenRouter key : ").strip() or os.getenv("OPENAI_API_KEY")
model    = input("ğŸ§   Model name               [meta-llama/llama-4-maverick] : ").strip() \
           or "meta-llama/llama-4-maverick"
chunk_tk = int(input("âœ‚ï¸  Chunk size (~tokens)    [2000]                       : ") or 2000)
style    = input("ğŸ›ï¸  bullets / paragraph     [bullets]                    : ").strip() or "bullets"
out_name = input("ğŸ’¾  Output file name         [summary]                    : ").strip() or "summary"

if not api_key:
    raise ValueError("âŒ  API key is required.")

client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£  Upload source PDF / TXT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“¤  Upload a .pdf or .txt file â€¦")
up_file = files.upload()
fname   = next(iter(up_file))
raw     = io.BytesIO(up_file[fname])
ext     = os.path.splitext(fname)[1].lower()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£  Extract text & chunk
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pdf_to_text(b: bytes) -> str:
    with pdfplumber.open(io.BytesIO(b)) as pdf:
        return "\n".join((p.extract_text() or "") for p in pdf.pages)

text = pdf_to_text(raw.getvalue()) if ext == ".pdf" else raw.read().decode(errors="ignore")
text = textwrap.dedent(text).replace("\r", "\n").strip()

max_chars = chunk_tk * 4       # â‰ˆ chars per token
chunks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]
print(f"ğŸ“š  {len(text):,} chars â†’ {len(chunks)} chunks.\n")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£  Prompt helper & chat call
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def prompt(txt: str) -> str:
    mode = "bullet-point" if style.lower().startswith("b") else "concise paragraph"
    return (
        f"Provide a {mode} summary of the text below. "
        "Preserve key facts, dates, and names.\n\n"
        f"Text:\n\"\"\"\n{txt}\n\"\"\""
    )

def chat(prompt: str) -> str:
    rsp = client.chat.completions.create(
        model      = model,
        messages   = [{"role": "user", "content": prompt}],
        temperature= 0.2,
        max_tokens = 512,
    )
    return rsp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5ï¸âƒ£  Summarise
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
summaries = []
for i, chunk in enumerate(tqdm(chunks, desc="ğŸ¤–  Summarising"), 1):
    try:
        summaries.append(chat(prompt(chunk[:4000])))
    except OpenAIError as e:
        summaries.append(f"[Chunk {i} failed: {e}]")
        print(f"âŒ  Chunk {i} failed.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6ï¸âƒ£  Merge & download
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
joiner  = "\n\n" if style.lower().startswith("p") else "\n"
summary = joiner.join(summaries)
outfile = out_name + ".txt"

with open(outfile, "w", encoding="utf-8") as f:
    f.write(summary)

files.download(outfile)
print("ğŸ‰  Summary downloaded â†’", outfile)