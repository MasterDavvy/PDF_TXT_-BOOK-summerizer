{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdqPcmZlHL7P"
      },
      "outputs": [],
      "source": [
        "# ▓▓  Single-model PDF/TXT summariser  (default: LLaMA-4 Maverick)  ▓▓\n",
        "# Install once per Colab session:\n",
        "# !pip install -q --upgrade openai pdfplumber tqdm\n",
        "!pip install -q --upgrade openai pdfplumber tqdm\n",
        "import os, io, textwrap, pdfplumber\n",
        "from google.colab import files\n",
        "from tqdm.auto import tqdm\n",
        "from openai import OpenAI, OpenAIError\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 1️⃣  Interactive settings (one primary model only)\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "print(\"✏️  Configure run — press Enter for values in [brackets]\")\n",
        "api_key  = input(\"🔑  OpenAI / OpenRouter key : \").strip() or os.getenv(\"OPENAI_API_KEY\")\n",
        "model    = input(\"🧠  Model name               [meta-llama/llama-4-maverick] : \").strip() \\\n",
        "           or \"meta-llama/llama-4-maverick\"\n",
        "chunk_tk = int(input(\"✂️  Chunk size (~tokens)    [2000]                       : \") or 2000)\n",
        "style    = input(\"🎛️  bullets / paragraph     [bullets]                    : \").strip() or \"bullets\"\n",
        "out_name = input(\"💾  Output file name         [summary]                    : \").strip() or \"summary\"\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"❌  API key is required.\")\n",
        "\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 2️⃣  Upload source PDF / TXT\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "print(\"\\n📤  Upload a .pdf or .txt file …\")\n",
        "up_file = files.upload()\n",
        "fname   = next(iter(up_file))\n",
        "raw     = io.BytesIO(up_file[fname])\n",
        "ext     = os.path.splitext(fname)[1].lower()\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 3️⃣  Extract text & chunk\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "def pdf_to_text(b: bytes) -> str:\n",
        "    with pdfplumber.open(io.BytesIO(b)) as pdf:\n",
        "        return \"\\n\".join((p.extract_text() or \"\") for p in pdf.pages)\n",
        "\n",
        "text = pdf_to_text(raw.getvalue()) if ext == \".pdf\" else raw.read().decode(errors=\"ignore\")\n",
        "text = textwrap.dedent(text).replace(\"\\r\", \"\\n\").strip()\n",
        "\n",
        "max_chars = chunk_tk * 4       # ≈ chars per token\n",
        "chunks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
        "print(f\"📚  {len(text):,} chars → {len(chunks)} chunks.\\n\")\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 4️⃣  Prompt helper & chat call\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "def prompt(txt: str) -> str:\n",
        "    mode = \"bullet-point\" if style.lower().startswith(\"b\") else \"concise paragraph\"\n",
        "    return (\n",
        "        f\"Provide a {mode} summary of the text below. \"\n",
        "        \"Preserve key facts, dates, and names.\\n\\n\"\n",
        "        f\"Text:\\n\\\"\\\"\\\"\\n{txt}\\n\\\"\\\"\\\"\"\n",
        "    )\n",
        "\n",
        "def chat(prompt: str) -> str:\n",
        "    rsp = client.chat.completions.create(\n",
        "        model      = model,\n",
        "        messages   = [{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature= 0.2,\n",
        "        max_tokens = 512,\n",
        "    )\n",
        "    return rsp.choices[0].message.content.strip()\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 5️⃣  Summarise\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "summaries = []\n",
        "for i, chunk in enumerate(tqdm(chunks, desc=\"🤖  Summarising\"), 1):\n",
        "    try:\n",
        "        summaries.append(chat(prompt(chunk[:4000])))\n",
        "    except OpenAIError as e:\n",
        "        summaries.append(f\"[Chunk {i} failed: {e}]\")\n",
        "        print(f\"❌  Chunk {i} failed.\")\n",
        "\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "# 6️⃣  Merge & download\n",
        "# ───────────────────────────────────────────────────────────────\n",
        "joiner  = \"\\n\\n\" if style.lower().startswith(\"p\") else \"\\n\"\n",
        "summary = joiner.join(summaries)\n",
        "outfile = out_name + \".txt\"\n",
        "\n",
        "with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(summary)\n",
        "\n",
        "files.download(outfile)\n",
        "print(\"🎉  Summary downloaded →\", outfile)"
      ]
    }
  ]
}